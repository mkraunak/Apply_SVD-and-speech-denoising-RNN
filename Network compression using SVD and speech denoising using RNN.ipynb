{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.0'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'tensorflow._api.v1.keras.datasets.mnist' from 'C:\\\\Anaconda3\\\\lib\\\\site-packages\\\\tensorflow\\\\_api\\\\v1\\\\keras\\\\datasets\\\\mnist\\\\__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist # 28*28images of hand written digits from 0 t0 9\n",
    "print(mnist)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "# Normalise the dataset\n",
    "\n",
    "x_train_N = tf.keras.utils.normalize(x_train, axis=1)\n",
    "x_test_N =  tf.keras.utils.normalize(x_test, axis=1)\n",
    "l_train=tf.keras.utils.to_categorical(y_train,10)\n",
    "l_test=tf.keras.utils.to_categorical(y_test,10)\n",
    "\n",
    "x_train_N=x_train_N.reshape(60000,784)\n",
    "x_test_N=x_test_N.reshape(10000,784)\n",
    "print(x_train_N.shape)\n",
    "\n",
    "print(x_test_N.shape)\n",
    "print(x_test_N.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model \n",
    "# Feed forward netwrok(SEQUENTIAL)\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.layers import Dropout\n",
    "\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "\n",
    "#First Hidden Layer \n",
    "model.add(layers.Dense(1024,activation='relu',kernel_initializer='he_normal',input_shape=(784,)))\n",
    "\n",
    "\n",
    "# 2nd hidden layer \n",
    "model.add(layers.Dense(1024, activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "\n",
    "\n",
    "# 3rd hidden layer \n",
    "model.add(layers.Dense(1024, activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "\n",
    "# 4th hidden layer \n",
    "model.add(layers.Dense(1024, activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "\n",
    "#5th hidden layer\n",
    "model.add(layers.Dense(1024, activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "\n",
    "\n",
    "# final layer, since it is multiclassification problem we are going to use softmax activation function which gives output as probablity distribution\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# parameters for the training of the model\n",
    "# neural netwrok tries to minimize the loss, loss is relationship to accuarcy \n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/90\n",
      " - 23s - loss: 0.2671 - acc: 0.9178 - val_loss: 0.1402 - val_acc: 0.9568\n",
      "Epoch 2/90\n",
      " - 22s - loss: 0.0958 - acc: 0.9707 - val_loss: 0.1329 - val_acc: 0.9607\n",
      "Epoch 3/90\n",
      " - 22s - loss: 0.0618 - acc: 0.9812 - val_loss: 0.0948 - val_acc: 0.9743\n",
      "Epoch 4/90\n",
      " - 22s - loss: 0.0428 - acc: 0.9866 - val_loss: 0.1191 - val_acc: 0.9670\n",
      "Epoch 5/90\n",
      " - 22s - loss: 0.0371 - acc: 0.9882 - val_loss: 0.1152 - val_acc: 0.9720\n",
      "Epoch 6/90\n",
      " - 22s - loss: 0.0330 - acc: 0.9896 - val_loss: 0.1202 - val_acc: 0.9726\n",
      "Epoch 7/90\n",
      " - 22s - loss: 0.0265 - acc: 0.9924 - val_loss: 0.1035 - val_acc: 0.9748\n",
      "Epoch 8/90\n",
      " - 22s - loss: 0.0187 - acc: 0.9942 - val_loss: 0.1201 - val_acc: 0.9746\n",
      "Epoch 9/90\n",
      " - 22s - loss: 0.0247 - acc: 0.9927 - val_loss: 0.1357 - val_acc: 0.9682\n",
      "Epoch 10/90\n",
      " - 23s - loss: 0.0214 - acc: 0.9937 - val_loss: 0.1306 - val_acc: 0.9692\n",
      "Epoch 11/90\n",
      " - 22s - loss: 0.0211 - acc: 0.9938 - val_loss: 0.1329 - val_acc: 0.9728\n",
      "Epoch 12/90\n",
      " - 22s - loss: 0.0146 - acc: 0.9960 - val_loss: 0.1408 - val_acc: 0.9743\n",
      "Epoch 13/90\n",
      " - 22s - loss: 0.0192 - acc: 0.9942 - val_loss: 0.1276 - val_acc: 0.9761\n",
      "Epoch 14/90\n",
      " - 22s - loss: 0.0112 - acc: 0.9966 - val_loss: 0.1381 - val_acc: 0.9727\n",
      "Epoch 15/90\n",
      " - 22s - loss: 0.0139 - acc: 0.9961 - val_loss: 0.1365 - val_acc: 0.9766\n",
      "Epoch 16/90\n",
      " - 22s - loss: 0.0110 - acc: 0.9969 - val_loss: 0.1393 - val_acc: 0.9744\n",
      "Epoch 17/90\n",
      " - 22s - loss: 0.0130 - acc: 0.9963 - val_loss: 0.1305 - val_acc: 0.9780\n",
      "Epoch 18/90\n",
      " - 22s - loss: 0.0081 - acc: 0.9980 - val_loss: 0.1235 - val_acc: 0.9782\n",
      "Epoch 19/90\n",
      " - 22s - loss: 0.0154 - acc: 0.9956 - val_loss: 0.1318 - val_acc: 0.9752\n",
      "Epoch 20/90\n",
      " - 21s - loss: 0.0123 - acc: 0.9968 - val_loss: 0.1365 - val_acc: 0.9737\n",
      "Epoch 21/90\n",
      " - 22s - loss: 0.0133 - acc: 0.9965 - val_loss: 0.1461 - val_acc: 0.9762\n",
      "Epoch 22/90\n",
      " - 22s - loss: 0.0077 - acc: 0.9977 - val_loss: 0.1412 - val_acc: 0.9771\n",
      "Epoch 23/90\n",
      " - 22s - loss: 0.0129 - acc: 0.9970 - val_loss: 0.1770 - val_acc: 0.9715\n",
      "Epoch 24/90\n",
      " - 22s - loss: 0.0150 - acc: 0.9956 - val_loss: 0.1380 - val_acc: 0.9746\n",
      "Epoch 25/90\n",
      " - 22s - loss: 0.0126 - acc: 0.9969 - val_loss: 0.1372 - val_acc: 0.9780\n",
      "Epoch 26/90\n",
      " - 22s - loss: 0.0138 - acc: 0.9966 - val_loss: 0.1152 - val_acc: 0.9795\n",
      "Epoch 27/90\n",
      " - 22s - loss: 0.0118 - acc: 0.9970 - val_loss: 0.1360 - val_acc: 0.9797\n",
      "Epoch 28/90\n",
      " - 23s - loss: 0.0107 - acc: 0.9974 - val_loss: 0.1368 - val_acc: 0.9778\n",
      "Epoch 29/90\n",
      " - 23s - loss: 0.0087 - acc: 0.9979 - val_loss: 0.1243 - val_acc: 0.9783\n",
      "Epoch 30/90\n",
      " - 22s - loss: 0.0107 - acc: 0.9975 - val_loss: 0.1505 - val_acc: 0.9765\n",
      "Epoch 31/90\n",
      " - 22s - loss: 0.0059 - acc: 0.9985 - val_loss: 0.1605 - val_acc: 0.9766\n",
      "Epoch 32/90\n",
      " - 22s - loss: 0.0082 - acc: 0.9980 - val_loss: 0.1511 - val_acc: 0.9779\n",
      "Epoch 33/90\n",
      " - 22s - loss: 0.0085 - acc: 0.9982 - val_loss: 0.1489 - val_acc: 0.9759\n",
      "Epoch 34/90\n",
      " - 22s - loss: 0.0094 - acc: 0.9974 - val_loss: 0.1445 - val_acc: 0.9770\n",
      "Epoch 35/90\n",
      " - 22s - loss: 0.0070 - acc: 0.9983 - val_loss: 0.1374 - val_acc: 0.9782\n",
      "Epoch 36/90\n",
      " - 22s - loss: 0.0108 - acc: 0.9979 - val_loss: 0.1558 - val_acc: 0.9789\n",
      "Epoch 37/90\n",
      " - 22s - loss: 0.0117 - acc: 0.9976 - val_loss: 0.1531 - val_acc: 0.9782\n",
      "Epoch 38/90\n",
      " - 23s - loss: 0.0123 - acc: 0.9973 - val_loss: 0.1469 - val_acc: 0.9757\n",
      "Epoch 39/90\n",
      " - 21s - loss: 0.0091 - acc: 0.9979 - val_loss: 0.1351 - val_acc: 0.9807\n",
      "Epoch 40/90\n",
      " - 22s - loss: 0.0043 - acc: 0.9990 - val_loss: 0.1296 - val_acc: 0.9791\n",
      "Epoch 41/90\n",
      " - 24s - loss: 0.0017 - acc: 0.9996 - val_loss: 0.1447 - val_acc: 0.9821\n",
      "Epoch 42/90\n",
      " - 23s - loss: 5.6597e-05 - acc: 1.0000 - val_loss: 0.1521 - val_acc: 0.9817\n",
      "Epoch 43/90\n",
      " - 22s - loss: 1.2096e-04 - acc: 1.0000 - val_loss: 0.1518 - val_acc: 0.9821\n",
      "Epoch 44/90\n",
      " - 42s - loss: 1.9088e-06 - acc: 1.0000 - val_loss: 0.1543 - val_acc: 0.9818\n",
      "Epoch 45/90\n",
      " - 48s - loss: 1.3100e-06 - acc: 1.0000 - val_loss: 0.1566 - val_acc: 0.9818\n",
      "Epoch 46/90\n",
      " - 49s - loss: 9.6541e-07 - acc: 1.0000 - val_loss: 0.1590 - val_acc: 0.9818\n",
      "Epoch 47/90\n",
      " - 48s - loss: 7.4669e-07 - acc: 1.0000 - val_loss: 0.1611 - val_acc: 0.9819\n",
      "Epoch 48/90\n",
      " - 48s - loss: 6.0027e-07 - acc: 1.0000 - val_loss: 0.1632 - val_acc: 0.9820\n",
      "Epoch 49/90\n",
      " - 47s - loss: 4.9671e-07 - acc: 1.0000 - val_loss: 0.1650 - val_acc: 0.9821\n",
      "Epoch 50/90\n",
      " - 49s - loss: 4.2286e-07 - acc: 1.0000 - val_loss: 0.1668 - val_acc: 0.9822\n",
      "Epoch 51/90\n",
      " - 46s - loss: 3.6746e-07 - acc: 1.0000 - val_loss: 0.1684 - val_acc: 0.9822\n",
      "Epoch 52/90\n",
      " - 45s - loss: 3.2499e-07 - acc: 1.0000 - val_loss: 0.1698 - val_acc: 0.9821\n",
      "Epoch 53/90\n",
      " - 47s - loss: 2.9174e-07 - acc: 1.0000 - val_loss: 0.1712 - val_acc: 0.9821\n",
      "Epoch 54/90\n",
      " - 46s - loss: 2.6567e-07 - acc: 1.0000 - val_loss: 0.1725 - val_acc: 0.9820\n",
      "Epoch 55/90\n",
      " - 45s - loss: 2.4410e-07 - acc: 1.0000 - val_loss: 0.1737 - val_acc: 0.9820\n",
      "Epoch 56/90\n",
      " - 45s - loss: 2.2649e-07 - acc: 1.0000 - val_loss: 0.1748 - val_acc: 0.9820\n",
      "Epoch 57/90\n",
      " - 53s - loss: 2.1191e-07 - acc: 1.0000 - val_loss: 0.1758 - val_acc: 0.9820\n",
      "Epoch 58/90\n",
      " - 42s - loss: 2.0000e-07 - acc: 1.0000 - val_loss: 0.1768 - val_acc: 0.9820\n",
      "Epoch 59/90\n",
      " - 43s - loss: 1.8967e-07 - acc: 1.0000 - val_loss: 0.1777 - val_acc: 0.9821\n",
      "Epoch 60/90\n",
      " - 42s - loss: 1.8102e-07 - acc: 1.0000 - val_loss: 0.1785 - val_acc: 0.9821\n",
      "Epoch 61/90\n",
      " - 42s - loss: 1.7374e-07 - acc: 1.0000 - val_loss: 0.1794 - val_acc: 0.9821\n",
      "Epoch 62/90\n",
      " - 42s - loss: 1.6740e-07 - acc: 1.0000 - val_loss: 0.1801 - val_acc: 0.9821\n",
      "Epoch 63/90\n",
      " - 42s - loss: 1.6191e-07 - acc: 1.0000 - val_loss: 0.1808 - val_acc: 0.9821\n",
      "Epoch 64/90\n",
      " - 42s - loss: 1.5715e-07 - acc: 1.0000 - val_loss: 0.1815 - val_acc: 0.9821\n",
      "Epoch 65/90\n",
      " - 42s - loss: 1.5304e-07 - acc: 1.0000 - val_loss: 0.1822 - val_acc: 0.9821\n",
      "Epoch 66/90\n",
      " - 42s - loss: 1.4938e-07 - acc: 1.0000 - val_loss: 0.1829 - val_acc: 0.9820\n",
      "Epoch 67/90\n",
      " - 43s - loss: 1.4623e-07 - acc: 1.0000 - val_loss: 0.1835 - val_acc: 0.9820\n",
      "Epoch 68/90\n",
      " - 42s - loss: 1.4342e-07 - acc: 1.0000 - val_loss: 0.1841 - val_acc: 0.9820\n",
      "Epoch 69/90\n",
      " - 42s - loss: 1.4093e-07 - acc: 1.0000 - val_loss: 0.1847 - val_acc: 0.9820\n",
      "Epoch 70/90\n",
      " - 42s - loss: 1.3877e-07 - acc: 1.0000 - val_loss: 0.1852 - val_acc: 0.9820\n",
      "Epoch 71/90\n",
      " - 42s - loss: 1.3683e-07 - acc: 1.0000 - val_loss: 0.1857 - val_acc: 0.9820\n",
      "Epoch 72/90\n",
      " - 42s - loss: 1.3510e-07 - acc: 1.0000 - val_loss: 0.1862 - val_acc: 0.9820\n",
      "Epoch 73/90\n",
      " - 54s - loss: 1.3357e-07 - acc: 1.0000 - val_loss: 0.1867 - val_acc: 0.9820\n",
      "Epoch 74/90\n",
      " - 42s - loss: 1.3220e-07 - acc: 1.0000 - val_loss: 0.1871 - val_acc: 0.9820\n",
      "Epoch 75/90\n",
      " - 42s - loss: 1.3100e-07 - acc: 1.0000 - val_loss: 0.1876 - val_acc: 0.9820\n",
      "Epoch 76/90\n",
      " - 43s - loss: 1.2987e-07 - acc: 1.0000 - val_loss: 0.1880 - val_acc: 0.9820\n",
      "Epoch 77/90\n",
      " - 45s - loss: 1.2888e-07 - acc: 1.0000 - val_loss: 0.1884 - val_acc: 0.9820\n",
      "Epoch 78/90\n",
      " - 48s - loss: 1.2799e-07 - acc: 1.0000 - val_loss: 0.1888 - val_acc: 0.9820\n",
      "Epoch 79/90\n",
      " - 47s - loss: 1.2719e-07 - acc: 1.0000 - val_loss: 0.1891 - val_acc: 0.9820\n",
      "Epoch 80/90\n",
      " - 51s - loss: 1.2647e-07 - acc: 1.0000 - val_loss: 0.1895 - val_acc: 0.9819\n",
      "Epoch 81/90\n",
      " - 41s - loss: 1.2582e-07 - acc: 1.0000 - val_loss: 0.1899 - val_acc: 0.9819\n",
      "Epoch 82/90\n",
      " - 41s - loss: 1.2522e-07 - acc: 1.0000 - val_loss: 0.1902 - val_acc: 0.9819\n",
      "Epoch 83/90\n",
      " - 41s - loss: 1.2469e-07 - acc: 1.0000 - val_loss: 0.1905 - val_acc: 0.9819\n",
      "Epoch 84/90\n",
      " - 41s - loss: 1.2423e-07 - acc: 1.0000 - val_loss: 0.1909 - val_acc: 0.9819\n",
      "Epoch 85/90\n",
      " - 40s - loss: 1.2379e-07 - acc: 1.0000 - val_loss: 0.1912 - val_acc: 0.9819\n",
      "Epoch 86/90\n",
      " - 40s - loss: 1.2340e-07 - acc: 1.0000 - val_loss: 0.1915 - val_acc: 0.9819\n",
      "Epoch 87/90\n",
      " - 40s - loss: 1.2303e-07 - acc: 1.0000 - val_loss: 0.1918 - val_acc: 0.9819\n",
      "Epoch 88/90\n",
      " - 40s - loss: 1.2271e-07 - acc: 1.0000 - val_loss: 0.1921 - val_acc: 0.9819\n",
      "Epoch 89/90\n",
      " - 40s - loss: 1.2241e-07 - acc: 1.0000 - val_loss: 0.1923 - val_acc: 0.9819\n",
      "Epoch 90/90\n",
      " - 41s - loss: 1.2213e-07 - acc: 1.0000 - val_loss: 0.1926 - val_acc: 0.9819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26f33d9acc0>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_N,l_train,epochs=90,batch_size=256,validation_split = 0.2,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 6s 631us/step\n",
      "The loss on the test data: \n",
      "0.19156952920535383\n",
      "Accuarcy of the model on the  test data:\n",
      "0.9821\n"
     ]
    }
   ],
   "source": [
    "# Calculated loss and accuracy on test data \n",
    "\n",
    "test_loss,test_acc=model.evaluate(x_test_N,l_test)\n",
    "print(\"The loss on the test data: \")\n",
    "print(test_loss)\n",
    "\n",
    "print(\"Accuarcy of the model on the  test data:\")\n",
    "print(test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 1024)\n",
      "[array([ 0.0297671 , -0.06989929, -0.00261092, ..., -0.06184525,\n",
      "       -0.02157955, -0.06911693], dtype=float32), array([ 0.03092804,  0.04490838, -0.07856093, ..., -0.13725804,\n",
      "       -0.09014807, -0.08507124], dtype=float32), array([-0.12538783, -0.03990418, -0.16335529, ..., -0.1462563 ,\n",
      "        0.19352268, -0.09538988], dtype=float32), array([ 0.036493  , -0.02243669,  0.05040984, ..., -0.05329393,\n",
      "        0.15030588,  0.08801403], dtype=float32), array([ 0.00244802,  0.25374588, -0.00566718, ..., -0.04153974,\n",
      "       -0.01120266,  0.01646812], dtype=float32), array([ 0.03701366, -0.15480103, -0.12137099, -0.02609856, -0.08618501,\n",
      "       -0.11707236, -0.14775993, -0.12712507,  0.3624093 ,  0.0990948 ],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# Find w and b of evry layer\n",
    "layer_weights = model.get_weights()\n",
    "\n",
    "B = layer_weights[1::2]\n",
    "# We can also find weight and biases by following method\n",
    "first_layer_weights=model.layers[0].get_weights()[0]\n",
    "first_layer_biases=model.layers[0].get_weights()[1]\n",
    "second_layer_weights=model.layers[1].get_weights()[0]\n",
    "second_layer_biases=model.layers[1].get_weights()[1]\n",
    "third_layer_weights=model.layers[2].get_weights()[0]\n",
    "third_layer_biases=model.layers[2].get_weights()[1]\n",
    "fourth_layer_weights=model.layers[3].get_weights()[0]\n",
    "fourth_layer_biases=model.layers[3].get_weights()[1]\n",
    "fifth_layer_weights=model.layers[4].get_weights()[0]\n",
    "fifth_layer_biases=model.layers[4].get_weights()[1]\n",
    "sixth_layer_weights=model.layers[5].get_weights()[0]\n",
    "sixth_layer_biases=model.layers[5].get_weights()[1]\n",
    "\n",
    "\n",
    "\n",
    "print(fifth_layer_weights.shape)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing singular value decomposition\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "u, S, v = LA.svd(first_layer_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = []\n",
    "U=[]\n",
    "s=[]\n",
    "V=[]\n",
    "for i in range(5):\n",
    "    U.append([])\n",
    "    s.append([])\n",
    "    V.append([])\n",
    "\n",
    "    \n",
    "# Reference was taken from stack overflow\n",
    "for i in range(5):\n",
    "    U[i],s[i],V[i] = LA.svd(layer_weights[i*2])\n",
    "    G = np.zeros((U[i].shape[0], V[i].shape[0]))\n",
    "    G[:U[i].shape[0], :U[i].shape[0]] = np.diag(s[i])\n",
    "    k.append((U[i]@G)@V[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approximation of new weight matrices\n",
    "#Reference was taken from stackoverflow\n",
    "W = []\n",
    "for d in [10, 20, 50, 100, 200]:\n",
    "    list = []\n",
    "    for i in range(5):\n",
    "        G = np.zeros((U[i].shape[0], V[i].shape[0]))\n",
    "        G[:d, :d] = np.diag(s[i][:d])\n",
    "        list.append((U[i]@G)@V[i])\n",
    "    W.append(list)\n",
    "W.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 252us/step\n",
      "10000/10000 [==============================] - 3s 255us/step\n",
      "10000/10000 [==============================] - 3s 257us/step\n",
      "10000/10000 [==============================] - 3s 255us/step\n",
      "10000/10000 [==============================] - 3s 256us/step\n",
      "10000/10000 [==============================] - 3s 255us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[69.87, 93.95, 97.68, 97.74000000000001, 97.75, 97.71]\n"
     ]
    }
   ],
   "source": [
    "# Plot of Accuracy vs d\n",
    "# Reference was taken from matplotlib documentation\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "acc_list = []\n",
    "for i in range(len(W)):\n",
    "    layer_weights[:10:2] = W[i]\n",
    "    model.set_weights(layer_weights)\n",
    "    acc_list.append(model.evaluate(x_test_N, l_test)[1]*100)\n",
    "\n",
    "values=['10', '20', '50', '100', '200','1024']\n",
    "plt.plot(values, acc_list) \n",
    "plt.xlabel('d')\n",
    "plt.ylabel('Accuracy of the Network')\n",
    "plt.show()\n",
    "print(acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference was taken from keras documentation  from https://keras.io/layers/writing-your-own-keras-layers/\n",
    "\n",
    "from keras.models import Model\n",
    "from keras import Input\n",
    "from keras.initializers import Constant\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer\n",
    "\n",
    "class MyLayer(Layer):\n",
    "    \n",
    "    def __init__(self, output_dim, U, Vbar, bias, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        self.U_mat = U\n",
    "        self.Vbar_mat = Vbar\n",
    "        self.b = bias\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        self.U = self.add_weight(name='U', \n",
    "                                      shape=self.U_mat.shape,\n",
    "                                      initializer=Constant(self.U_mat),\n",
    "                                      trainable=True)\n",
    "        self.Vbar = self.add_weight(name='Vbar', \n",
    "                                      shape=self.Vbar_mat.shape,\n",
    "                                      initializer=Constant(self.Vbar_mat),\n",
    "                                      trainable=True)\n",
    "        \n",
    "        self.bias = self.add_weight(name = 'bias',\n",
    "                                      shape = (self.output_dim,),\n",
    "                                      initializer=Constant(self.b),\n",
    "                                      trainable=True)\n",
    "        \n",
    "        super(MyLayer, self).build(input_shape)  \n",
    "\n",
    "    def call(self, x):\n",
    "        return K.relu(K.dot(x, K.dot(self.U, self.Vbar)) + self.bias)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "last_layer = model.get_layer(index=5)\n",
    "sixth_layer_weights=model.layers[5].get_weights()[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Singular Value Decompos on each weight matrix\n",
    "\n",
    "k1 = []\n",
    "u=[]\n",
    "s=[]\n",
    "v=[]\n",
    "for i in range(5):\n",
    "    u.append([])\n",
    "    s.append([])\n",
    "    v.append([])\n",
    "for i in range(5):\n",
    "    u[i],s[i],v[i] = LA.svd(layer_weights[i*2])\n",
    "    g = np.zeros((u[i].shape[0], v[i].shape[0]))\n",
    "    g[:20, :20] = np.diag(s[i][:20])\n",
    "    k1.append((u[i], g@v[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New model\n",
    "#Reference was taken from stack overflow and keras documentation \n",
    "input = Input(shape = (28*28,))\n",
    "x = MyLayer(1024, U = k1[0][0], Vbar = k1[0][1], bias = B[0])(input)\n",
    "x = MyLayer(1024, U = k1[1][0], Vbar = k1[1][1], bias = B[1])(x)\n",
    "x = MyLayer(1024, U = k1[2][0], Vbar = k1[2][1], bias = B[2])(x)\n",
    "x = MyLayer(1024, U = k1[3][0], Vbar = k1[3][1], bias = B[3])(x)\n",
    "x = MyLayer(1024, U = k1[4][0], Vbar = k1[4][1], bias = B[4])(x)\n",
    "output = last_layer(x)\n",
    "new_model = Model(input, output)\n",
    "new_model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      " - 64s - loss: 1.4348 - acc: 0.4731 - val_loss: 0.4600 - val_acc: 0.8759\n",
      "Epoch 2/15\n",
      " - 59s - loss: 0.3030 - acc: 0.9148 - val_loss: 0.2190 - val_acc: 0.9367\n",
      "Epoch 3/15\n",
      " - 113s - loss: 0.1567 - acc: 0.9550 - val_loss: 0.1462 - val_acc: 0.9593\n",
      "Epoch 4/15\n",
      " - 30s - loss: 0.1005 - acc: 0.9710 - val_loss: 0.1205 - val_acc: 0.9656\n",
      "Epoch 5/15\n",
      " - 30s - loss: 0.0800 - acc: 0.9765 - val_loss: 0.1391 - val_acc: 0.9630\n",
      "Epoch 6/15\n",
      " - 29s - loss: 0.0663 - acc: 0.9808 - val_loss: 0.1308 - val_acc: 0.9643\n",
      "Epoch 7/15\n",
      " - 30s - loss: 0.0571 - acc: 0.9826 - val_loss: 0.1123 - val_acc: 0.9698\n",
      "Epoch 8/15\n",
      " - 29s - loss: 0.0514 - acc: 0.9849 - val_loss: 0.1351 - val_acc: 0.9698\n",
      "Epoch 9/15\n",
      " - 28s - loss: 0.0451 - acc: 0.9866 - val_loss: 0.1302 - val_acc: 0.9689\n",
      "Epoch 10/15\n",
      " - 28s - loss: 0.0434 - acc: 0.9869 - val_loss: 0.1304 - val_acc: 0.9693\n",
      "Epoch 11/15\n",
      " - 26s - loss: 0.0381 - acc: 0.9890 - val_loss: 0.1159 - val_acc: 0.9708\n",
      "Epoch 12/15\n",
      " - 27s - loss: 0.0364 - acc: 0.9890 - val_loss: 0.1117 - val_acc: 0.9729\n",
      "Epoch 13/15\n",
      " - 29s - loss: 0.0335 - acc: 0.9901 - val_loss: 0.1219 - val_acc: 0.9718\n",
      "Epoch 14/15\n",
      " - 29s - loss: 0.0277 - acc: 0.9913 - val_loss: 0.1350 - val_acc: 0.9695\n",
      "Epoch 15/15\n",
      " - 30s - loss: 0.0299 - acc: 0.9909 - val_loss: 0.1292 - val_acc: 0.9715\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26f3725ef28>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.fit(x_train_N,l_train,epochs=15,batch_size=1024,validation_split = 0.2,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 31s 3ms/step\n",
      "The loss on the test data: \n",
      "0.11712642328971996\n",
      "Accuarcy of the new model on the  test data:\n",
      "0.9739\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on test data\n",
    "test_loss,test_acc=new_model.evaluate(x_test_N,l_test)\n",
    "print(\"The loss on the test data: \")\n",
    "print(test_loss)\n",
    "\n",
    "print(\"Accuarcy of the new model on the  test data:\")\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Question Number 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "#Reference from stackoverflow \n",
    "#Input file\n",
    "data_X=[]\n",
    "for i in range(10):\n",
    "    s, sr=librosa.load(r'timit-homework/tr/trx000' + str(i) + '.wav', sr=None)\n",
    "    S=librosa.stft(s, n_fft=1024, hop_length=512)\n",
    "    data_X.append(S)\n",
    "    \n",
    "#Signal file\n",
    "signal_X=[]                      \n",
    "for i in range(10):\n",
    "    sn, sr=librosa.load(r'timit-homework/tr/trs000' + str(i) + '.wav', sr=None)\n",
    "    X=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
    "    signal_X.append(X)\n",
    "    \n",
    "#noise file                       \n",
    "noise_X=[]                      \n",
    "for i in range(10):\n",
    "    sm, sr=librosa.load(r'timit-homework/tr/trn000' + str(i) + '.wav', sr=None)\n",
    "    Xm=librosa.stft(sm, n_fft=1024, hop_length=512)\n",
    "    noise_X.append(Xm)\n",
    "print(len(data_X))\n",
    "print(len(noise_X))\n",
    "print(len(signal_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1200\n",
      "1200\n",
      "1200\n"
     ]
    }
   ],
   "source": [
    "  # Training data set \n",
    "for i in range(10, 100):\n",
    "    s1, sr=librosa.load(r'timit-homework/tr/trx00' + str(i) + '.wav', sr=None)\n",
    "    S1=librosa.stft(s1, n_fft=1024, hop_length=512)\n",
    "    data_X.append(S1)\n",
    "    \n",
    "                    \n",
    "for i in range(10,100):\n",
    "    sn1, sr=librosa.load(r'timit-homework/tr/trs00' + str(i) + '.wav', sr=None)\n",
    "    X1=librosa.stft(sn1, n_fft=1024, hop_length=512)\n",
    "    signal_X.append(X1)\n",
    "                     \n",
    "for i in range(10,100):\n",
    "    sm1, sr=librosa.load(r'timit-homework/tr/trn00' + str(i) + '.wav', sr=None)\n",
    "    Xm1=librosa.stft(sm1, n_fft=1024, hop_length=512)\n",
    "    noise_X.append(Xm1)\n",
    "###\n",
    " \n",
    "print(len(data_X))\n",
    "print(len(noise_X))\n",
    "print(len(signal_X))\n",
    "\n",
    "for i in range(100, 1000):\n",
    "    s2, sr=librosa.load(r'timit-homework/tr/trx0' + str(i) + '.wav', sr=None)\n",
    "    S2=librosa.stft(s2, n_fft=1024, hop_length=512)\n",
    "    data_X.append(S2)\n",
    "    \n",
    "    sn2, sr=librosa.load(r'timit-homework/tr/trs0' + str(i) + '.wav', sr=None)\n",
    "    X2=librosa.stft(sn2, n_fft=1024, hop_length=512)\n",
    "    signal_X.append(X2)\n",
    "                     \n",
    "    sm2, sr=librosa.load(r'timit-homework/tr/trn0' + str(i) + '.wav', sr=None)\n",
    "    Xm2=librosa.stft(sm2, n_fft=1024, hop_length=512)\n",
    "    noise_X.append(Xm2)\n",
    "\n",
    "print(len(data_X))\n",
    "print(len(noise_X))\n",
    "print(len(signal_X))\n",
    " ###   \n",
    "for i in range(1000, 1200):\n",
    "    s3, sr=librosa.load(r'timit-homework/tr/trx' + str(i) + '.wav', sr=None)\n",
    "    S3=librosa.stft(s3, n_fft=1024, hop_length=512)\n",
    "    data_X.append(S3)\n",
    "    \n",
    "    sn3, sr=librosa.load(r'timit-homework/tr/trs' + str(i) + '.wav', sr=None)\n",
    "    X3=librosa.stft(sn3, n_fft=1024, hop_length=512)\n",
    "    signal_X.append(X3)\n",
    "                     \n",
    "    sm3, sr=librosa.load(r'timit-homework/tr/trn' + str(i) + '.wav', sr=None)\n",
    "    Xm3=librosa.stft(sm3, n_fft=1024, hop_length=512)\n",
    "    noise_X.append(Xm3)\n",
    "print(len(data_X))\n",
    "print(len(noise_X))\n",
    "print(len(signal_X))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Data Set\n",
    "mod_data_X = []\n",
    "for i in data_X:\n",
    "    mod_data_X.append(np.abs(i).transpose())\n",
    "mod_Signal_X = []\n",
    "for i in signal_X:\n",
    "    mod_Signal_X.append(np.abs(i).transpose())\n",
    "mod_noise_X = []\n",
    "for i in noise_X:\n",
    "    mod_noise_X.append(np.abs(i).transpose())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation Data set\n",
    "\n",
    "\n",
    "data_V=[]\n",
    "signal_V=[]\n",
    "noise_V=[]\n",
    "\n",
    "\n",
    "for i in range(0,10):\n",
    "    v1, sr=librosa.load('timit-homework/v/vx000' + str(i) + '.wav', sr=None) \n",
    "    V1=librosa.stft(v1, n_fft=1024, hop_length=512) \n",
    "    data_V.append(V1)  \n",
    "    vs1, sr=librosa.load('timit-homework/v/vs000' + str(i) + '.wav', sr=None) \n",
    "    VS1=librosa.stft(vs1, n_fft=1024, hop_length=512)\n",
    "    signal_V.append(VS1)    \n",
    "    vn1, sr=librosa.load('timit-homework/v/vn000' + str(i) + '.wav', sr=None) \n",
    "    VN1=librosa.stft(vn1, n_fft=1024, hop_length=512) \n",
    "    noise_V.append(VN1)\n",
    "for i in range(10, 100):\n",
    "    \n",
    "    \n",
    "    v1, sr=librosa.load('timit-homework/v/vx00' + str(i) + '.wav', sr=None) \n",
    "    V1=librosa.stft(v1, n_fft=1024, hop_length=512) \n",
    "    data_V.append(V1)    \n",
    "    vs1, sr=librosa.load('timit-homework/v/vs00' + str(i) + '.wav', sr=None) \n",
    "    VS1=librosa.stft(vs1, n_fft=1024, hop_length=512)\n",
    "    signal_V.append(VS1)    \n",
    "    vn1, sr=librosa.load('timit-homework/v/vn00' + str(i) + '.wav', sr=None) \n",
    "    VN1=librosa.stft(vn1, n_fft=1024, hop_length=512) \n",
    "    noise_V.append(VN1)    \n",
    "for i in range(100, 1000):\n",
    "    \n",
    "    \n",
    "    v1, sr=librosa.load('timit-homework/v/vx0' + str(i) + '.wav', sr=None) \n",
    "    V1=librosa.stft(v1, n_fft=1024, hop_length=512) \n",
    "    data_V.append(V1)    \n",
    "    vs1, sr=librosa.load('timit-homework/v/vs0' + str(i) + '.wav', sr=None) \n",
    "    VS1=librosa.stft(vs1, n_fft=1024, hop_length=512)\n",
    "    signal_V.append(VS1)    \n",
    "    vn1, sr=librosa.load('timit-homework/v/vn0' + str(i) + '.wav', sr=None) \n",
    "    VN1=librosa.stft(vn1, n_fft=1024, hop_length=512) \n",
    "    noise_V.append(VN1)\n",
    "for i in range(1000, 1200):\n",
    "    \n",
    "    v1, sr=librosa.load('timit-homework/v/vx' + str(i) + '.wav', sr=None) \n",
    "    V1=librosa.stft(v1, n_fft=1024, hop_length=512) \n",
    "    data_V.append(V1)   \n",
    "    vs1, sr=librosa.load('timit-homework/v/vs' + str(i) + '.wav', sr=None) \n",
    "    VS1=librosa.stft(vs1, n_fft=1024, hop_length=512)\n",
    "    signal_V.append(VS1)    \n",
    "    vn1, sr=librosa.load('timit-homework/v/vn' + str(i) + '.wav', sr=None) \n",
    "    VN1=librosa.stft(vn1, n_fft=1024, hop_length=512) \n",
    "    noise_V.append(VN1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the magnitude and taking transpose of the absolute validation dataset\n",
    "V_data_mod = []\n",
    "for i in data_V:\n",
    "    V_data_mod.append(np.abs(i).transpose())\n",
    "V_Signal_mod = []\n",
    "for i in signal_V:\n",
    "    V_Signal_mod.append(np.abs(i).transpose())\n",
    "V_Noise_mod = []\n",
    "for i in noise_V:\n",
    "    V_Noise_mod.append(np.abs(i).transpose())\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ideal Binary Mask on training data\n",
    "IBM = []\n",
    "for i in range(len(mod_data_X)):\n",
    "    IBM.append(mod_Signal_X[i] - mod_noise_X[i])\n",
    "    \n",
    "for i in range(len(IBM)):\n",
    "    IBM[i][IBM[i]>=0] = 1\n",
    "    IBM[i][IBM[i]<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ideal Binary Mask on validation data set\n",
    "Valid_IBM = []\n",
    "for i in range(len(V_data_mod)):\n",
    "    Valid_IBM.append(V_Signal_mod[i] - V_Noise_mod[i])\n",
    "    \n",
    "for i in range(len(Valid_IBM)):\n",
    "    Valid_IBM[i][Valid_IBM[i]>=0] = 1\n",
    "    Valid_IBM[i][Valid_IBM[i]<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRU Model\n",
    "# Reference from stack overflow\n",
    "from keras import models\n",
    "from keras.layers import Dense, GRU, TimeDistributed, InputLayer, Layer\n",
    "from keras.models import Sequential\n",
    "model_g = Sequential()\n",
    "model_g.add(InputLayer(input_shape= (None, 513)))\n",
    "model_g.add(GRU(513, return_sequences = True, dropout = 0.1, recurrent_dropout = 0.3))\n",
    "model_g.add(GRU(513, return_sequences = True, recurrent_dropout = 0.3))\n",
    "model_g.add(TimeDistributed(Dense(513, activation = 'sigmoid')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_g.compile(optimizer='adam',loss= 'binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating batches of 10 samples of data\n",
    "def sample(mod_data_X, IBM):\n",
    "    while True:\n",
    "        for i in range(0, len(mod_data_X), 10):\n",
    "            if i >= len(mod_data_X)-10:\n",
    "                i = 0\n",
    "            batch = np.stack(mod_data_X[i:i+10])\n",
    "            label = np.stack(IBM[i:i+10])\n",
    "            yield batch, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mod_data_X)\n",
    "type(IBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "120/120 [==============================] - 161s 1s/step - loss: 0.3417 - acc: 0.8479\n",
      "Epoch 2/40\n",
      "120/120 [==============================] - 162s 1s/step - loss: 0.3407 - acc: 0.8483\n",
      "Epoch 3/40\n",
      "120/120 [==============================] - 161s 1s/step - loss: 0.3404 - acc: 0.8485\n",
      "Epoch 4/40\n",
      "120/120 [==============================] - 163s 1s/step - loss: 0.3388 - acc: 0.8496\n",
      "Epoch 5/40\n",
      "120/120 [==============================] - 161s 1s/step - loss: 0.3367 - acc: 0.8503\n",
      "Epoch 6/40\n",
      "120/120 [==============================] - 161s 1s/step - loss: 0.3371 - acc: 0.8502\n",
      "Epoch 7/40\n",
      "120/120 [==============================] - 162s 1s/step - loss: 0.3373 - acc: 0.8501\n",
      "Epoch 8/40\n",
      "120/120 [==============================] - 6165s 51s/step - loss: 0.3364 - acc: 0.8504\n",
      "Epoch 9/40\n",
      "120/120 [==============================] - 163s 1s/step - loss: 0.3361 - acc: 0.8506\n",
      "Epoch 10/40\n",
      "120/120 [==============================] - 162s 1s/step - loss: 0.3349 - acc: 0.8511\n",
      "Epoch 11/40\n",
      "120/120 [==============================] - 161s 1s/step - loss: 0.3329 - acc: 0.8522\n",
      "Epoch 12/40\n",
      "120/120 [==============================] - 163s 1s/step - loss: 0.3306 - acc: 0.8534\n",
      "Epoch 13/40\n",
      "120/120 [==============================] - 163s 1s/step - loss: 0.3302 - acc: 0.8535\n",
      "Epoch 14/40\n",
      "120/120 [==============================] - 179s 1s/step - loss: 0.3306 - acc: 0.8534\n",
      "Epoch 15/40\n",
      "120/120 [==============================] - 179s 1s/step - loss: 0.3304 - acc: 0.8534\n",
      "Epoch 16/40\n",
      "120/120 [==============================] - 172s 1s/step - loss: 0.3299 - acc: 0.8537\n",
      "Epoch 17/40\n",
      "120/120 [==============================] - 162s 1s/step - loss: 0.3281 - acc: 0.8546\n",
      "Epoch 18/40\n",
      "120/120 [==============================] - 168s 1s/step - loss: 0.3259 - acc: 0.8556\n",
      "Epoch 19/40\n",
      "120/120 [==============================] - 175s 1s/step - loss: 0.3244 - acc: 0.8563\n",
      "Epoch 20/40\n",
      "120/120 [==============================] - 179s 1s/step - loss: 0.3238 - acc: 0.8567\n",
      "Epoch 21/40\n",
      "120/120 [==============================] - 179s 1s/step - loss: 0.3235 - acc: 0.8569\n",
      "Epoch 22/40\n",
      "120/120 [==============================] - 176s 1s/step - loss: 0.3238 - acc: 0.8567\n",
      "Epoch 23/40\n",
      "120/120 [==============================] - 176s 1s/step - loss: 0.3226 - acc: 0.8573\n",
      "Epoch 24/40\n",
      "120/120 [==============================] - 175s 1s/step - loss: 0.3222 - acc: 0.8574\n",
      "Epoch 25/40\n",
      "120/120 [==============================] - 165s 1s/step - loss: 0.3215 - acc: 0.8578\n",
      "Epoch 26/40\n",
      "120/120 [==============================] - 193s 2s/step - loss: 0.3210 - acc: 0.8580\n",
      "Epoch 27/40\n",
      "120/120 [==============================] - 332s 3s/step - loss: 0.3194 - acc: 0.8588\n",
      "Epoch 28/40\n",
      "120/120 [==============================] - 328s 3s/step - loss: 0.3173 - acc: 0.8598\n",
      "Epoch 29/40\n",
      "120/120 [==============================] - 342s 3s/step - loss: 0.3163 - acc: 0.8604\n",
      "Epoch 30/40\n",
      "120/120 [==============================] - 348s 3s/step - loss: 0.3155 - acc: 0.8607\n",
      "Epoch 31/40\n",
      "120/120 [==============================] - 353s 3s/step - loss: 0.3160 - acc: 0.8605\n",
      "Epoch 32/40\n",
      "120/120 [==============================] - 346s 3s/step - loss: 0.3152 - acc: 0.8608\n",
      "Epoch 33/40\n",
      "120/120 [==============================] - 357s 3s/step - loss: 0.3152 - acc: 0.8609\n",
      "Epoch 34/40\n",
      "120/120 [==============================] - 361s 3s/step - loss: 0.3153 - acc: 0.8609\n",
      "Epoch 35/40\n",
      "120/120 [==============================] - 359s 3s/step - loss: 0.3162 - acc: 0.8603\n",
      "Epoch 36/40\n",
      "120/120 [==============================] - 369s 3s/step - loss: 0.3161 - acc: 0.8604\n",
      "Epoch 37/40\n",
      "120/120 [==============================] - 362s 3s/step - loss: 0.3146 - acc: 0.8612\n",
      "Epoch 38/40\n",
      "120/120 [==============================] - 369s 3s/step - loss: 0.3145 - acc: 0.8611\n",
      "Epoch 39/40\n",
      "120/120 [==============================] - 373s 3s/step - loss: 0.3145 - acc: 0.8612\n",
      "Epoch 40/40\n",
      "120/120 [==============================] - 334s 3s/step - loss: 0.3146 - acc: 0.8612\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26f6362fe10>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training model\n",
    "model_g.fit_generator(sample(mod_data_X, IBM),steps_per_epoch = len(mod_data_X)/10, epochs = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = []\n",
    "for i in range(0, len(V_data_mod), 10):\n",
    "    pred_valid = model_g.predict(np.stack(V_data_mod[i:i+10]))\n",
    "    # Denoising validation files using Ideal Binary Mask predictd by the model\n",
    "    for j in range(10):\n",
    "        \n",
    "        trans_v=pred_valid[j].transpose()\n",
    "        Mul=np.multiply(trans_v,data_V[i:i+10][j])\n",
    "\n",
    "        valid.extend([Mul])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred_Valid_Signal=[]\n",
    "for i in valid:\n",
    "    Pred_Valid_Signal.append(librosa.istft(i, hop_length=512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Signal to Noise ratio on Validation data set is: 12.940772611896197\n"
     ]
    }
   ],
   "source": [
    "#Calculation of SNR on validation data set\n",
    "SNR = []\n",
    "for i in range(len(valid)):\n",
    "    SNR.append(10*np.log10(np.add.reduce(np.abs(signal_V[i])**2, axis = None)/np.add.reduce((np.abs(signal_V[i])-np.abs(valid[i]))**2, axis =None)))\n",
    "\n",
    "print('The Signal to Noise ratio on Validation data set is:', np.mean(SNR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation model\n",
    "#model_g.fit_generator(sample(mod_data_V,IBM_V),steps_per_epoch=len(mod_data_V)/10,epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading Test Data File\n",
    "\n",
    "import numpy as np\n",
    "import librosa\n",
    "#Reference from stackoverflow \n",
    "#Input file\n",
    "data_test=[]\n",
    "for i in range(10):\n",
    "    s, sr=librosa.load(r'timit-homework/te/tex000' + str(i) + '.wav', sr=None)\n",
    "    S=librosa.stft(s, n_fft=1024, hop_length=512)\n",
    "    data_test.append(S)\n",
    "    \n",
    "for i in range(10, 100):\n",
    "    s1, sr=librosa.load(r'timit-homework/te/tex00' + str(i) + '.wav', sr=None)\n",
    "    S1=librosa.stft(s1, n_fft=1024, hop_length=512)\n",
    "    data_test.append(S1)\n",
    "for i in range(100, 400):\n",
    "    s2, sr=librosa.load(r'timit-homework/te/tex0' + str(i) + '.wav', sr=None)\n",
    "    S2=librosa.stft(s2, n_fft=1024, hop_length=512)\n",
    "    data_test.append(S2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating magnitude of test data\n",
    "\n",
    "test_data_mod = []\n",
    "for i in data_test:\n",
    "    test_data_mod.append(np.abs(i).transpose())\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting Ideal Binary Mask for test samples\n",
    "test = []\n",
    "for i in range(0, len(test_data_mod), 10):\n",
    "    pred_test = model_g.predict(np.stack(test_data_mod[i:i+10]))\n",
    "\n",
    "    for j in range(10):\n",
    "        trans_test=pred_test[j].transpose()\n",
    "        Mul_test=np.multiply(trans_test,data_test[i:i+10][j])\n",
    "\n",
    "        test.extend([Mul_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing Inverse Short Time Fourier Transform to get the output signal\n",
    "test_output=[]\n",
    "for i in test:\n",
    "    test_output.append(librosa.istft(i, hop_length=512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the cleaned test files\n",
    "i = 0\n",
    "for j in test_output:\n",
    "    librosa.output.write_wav(r'test_file_cleaned' + str(i) + '.wav', j, sr)\n",
    "    i+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
